---
# Maintenance playbook for inference nodes

- name: System Updates
  hosts: inference_nodes
  become: yes
  tags: 
    - update
  tasks:
    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Upgrade all packages
      apt:
        upgrade: dist
        autoremove: yes
        autoclean: yes
      register: apt_upgrade

    - name: Check if reboot is required
      stat:
        path: /var/run/reboot-required
      register: reboot_required

    - name: Reboot if required
      reboot:
        reboot_timeout: 300
        post_reboot_delay: 30
      when: reboot_required.stat.exists

- name: Restart Services
  hosts: inference_nodes
  become: yes
  tags:
    - restart
  tasks:
    - name: Restart Docker service
      systemd:
        name: docker
        state: restarted
      tags:
        - docker

    - name: Restart vLLM service
      systemd:
        name: vllm
        state: restarted
      tags:
        - vllm

- name: Clean Docker Resources
  hosts: inference_nodes
  become: yes
  tags:
    - clean
  tasks:
    - name: Remove stopped containers
      command: docker container prune -f
      changed_when: true

    - name: Remove dangling images
      command: docker image prune -f
      changed_when: true

    - name: Remove unused volumes
      command: docker volume prune -f
      changed_when: true

    - name: Clean vLLM cache
      file:
        path: /opt/inference/cache
        state: "{{ item }}"
      loop:
        - absent
        - directory
      tags:
        - vllm_cache

- name: Check System Status
  hosts: inference_nodes
  become: yes
  tags:
    - status
  tasks:
    - name: Check system uptime
      command: uptime
      register: uptime
      changed_when: false

    - name: Display uptime
      debug:
        var: uptime.stdout_lines

    - name: Check available disk space
      command: df -h /
      register: disk_space
      changed_when: false

    - name: Display disk space
      debug:
        var: disk_space.stdout_lines

    - name: Check GPU status with nvidia-smi
      command: nvidia-smi
      register: nvidia_smi
      changed_when: false
      ignore_errors: true

    - name: Display GPU status
      debug:
        var: nvidia_smi.stdout_lines
      when: nvidia_smi.rc == 0

    - name: Check Docker containers
      command: docker ps -a
      register: docker_ps
      changed_when: false

    - name: Display Docker containers
      debug:
        var: docker_ps.stdout_lines

    - name: Check vLLM server logs
      command: journalctl -u vllm.service -n 20
      register: vllm_logs
      changed_when: false

    - name: Display vLLM logs
      debug:
        var: vllm_logs.stdout_lines